{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Load the project's data\n",
    "data_climate = pd.read_csv('data_fortaleza-CE.csv')\n",
    "data_climate.columns = ['codigo_estacao','data','hora','temp_inst','temp_max','temp_min','umid_inst','umid_max','umid_min','pto_orvalho_inst','pto_orvalho_max','pto_orvalho_min','pressao','pressao_max','pressao_min','vento_direcao','vento_vel','vento_rajada','radiacao','precipitacao']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "#using neural networks recurrents\n",
    "#network short memory with LSTM, she use backpropagation through time and have memory block instead neruons.\n",
    "dataset = pd.DataFrame(data_climate[['hora','temp_inst','umid_inst','pto_orvalho_inst','pressao','vento_rajada','vento_direcao','vento_vel']])\n",
    "dataset = dataset.values\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "#To reduce the data from [0,1] scale with pre-preprocessing\n",
    "#Normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test sets\n",
    "train_size = int(len(dataset)*0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train,test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "print('Train dimensions ->{}'.format(train.shape))\n",
    "print('Test dimensions ->{}'.format(test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To define a new dataset\n",
    "args : the olg dataset(np array),\n",
    "       look_back(you select times before and number steps for prevent the next period)\n",
    "'''\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_new_dataset(dataset,look_back=1):\n",
    "    dataX,dataY = [],[]\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back),0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+look_back,0])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this new_dataset, the fisrt columns is X=t and second is Y=t+1\n",
    "new_dataset = create_new_dataset(dataset)\n",
    "\n",
    "#reshape into X = t and Y = t+1\n",
    "look_back = 1\n",
    "trainX,trainY = create_new_dataset(train,look_back)\n",
    "testX,testY = create_new_dataset(test,look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LSTM needs the X(inputs) args this form: [samples,time steps, features], \n",
    "now the data is = [samples,features], we uses the numpy.reshape() for reshape\n",
    "'''\n",
    "#reshape input to be [samples,time steps, features]\n",
    "trainX = np.reshape(trainX,(trainX.shape[0],1,trainX.shape[1]))\n",
    "testX = np.reshape(testX,(testX.shape[0],1,testX.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, the LSTM!!!\n",
    "\n",
    "LSTM needs 3 layers : 1ºinput layer\n",
    "                      2ºhidden layer with 4 LSTM blocks or neural\n",
    "                      3ºoutput layer\n",
    "\n",
    " - General is just one output;\n",
    " - Sigmoid function is used for LSTM blocks;\n",
    " - For default, is 100 epoch by train.\n",
    "'''\n",
    "\n",
    "#To ignore the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#create and fir the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4,input_shape=(1,look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "model.fit(trainX,trainY,epochs=300,batch_size=1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try inverse predictions\n",
    "\n",
    "#make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:,:] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:,:] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "plt.rcParams['figure.figsize'] = (152,12)\n",
    "plt.plot(scaler.inverse_transform(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictPlot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredictPlot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_climate.vento_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_climate.vento_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
